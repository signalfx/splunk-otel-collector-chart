# Configurable parameters and default values for splunk-otel-collector.
# This is a YAML-formatted file.
# Declared variables will be passed into templates.

################################################################################
# clusterName is a REQUIRED field. It can be set to an arbitrary value
# that identifies this K8s cluster in SignalFx. The value will be associated
# with every trace, metric and log as "k8s.cluster.name" metadata attribute.
################################################################################

clusterName: k8s-cluster


################################################################################
# Splunk SignalFx backend configuration
################################################################################

# The SignalFx realm to send telemetry data to. If set, the values of `ingestUrl`
# and `apiUrl` will be automatically set based on this
# realm value. If not set, it defaults to the original "us0" realm.
splunkRealm: us0

# (REQUIRED) SignalFx org access token.
splunkAccessToken:

# SignalFx ingest URL, default: "https://ingest.<realm>.signalfx.com".
ingestUrl:

# The SignalFx API URL, default: "https://api.<realm>.signalfx.com".
apiUrl:

################################################################################
# Cloud provider, if any, the collector is running on. Leave empty for none/other.
# - "aws" (Amazon Web Services)
# - "gcp" (Google Cloud Platform)
# - "azure" (Microsoft Azure)
################################################################################

provider: ""

################################################################################
# Kubernetes distribution being run. Leave empty for other.
# - "eks" (Amazon Elastic Kubernetes Service)
# - "gke" (Google Google Kubernetes Engine)
# - "aks" (Azure Kubernetes Service)
################################################################################

distro: ""

################################################################################
# Telemetry configuration.
# By default metrics, traces and logs are collected from the k8s cluster.
# It's possible to disable any kind of telemetry, if it's not needed.
################################################################################

metricsEnabled: true
tracesEnabled: true
logsEnabled: true

################################################################################
# Optional "environment" parameter that will be added to all the telemetry
# data (traces/logs/metrics) as an attribute. It will allow Splunk Observability
# users to investigate data coming from different source separately.
################################################################################

# environment: production

################################################################################
# Optional: Automatic detection of additional metric sources.
# Set autodetect.prometheus=true if you want the otel-collector agent to scrape
# prometheus metrics from pods that have prometheus-style annotations like
# "prometheus.io/scrape".
# Set autodetect.istio=true in istio environment.
################################################################################

autodetect:
  prometheus: false
  istio: false

################################################################################
# Optional: Configuration for additional metadata that will be added to all the
# telemetry as extra attributes.
################################################################################

extraAttributes:

  # Labels that will be collected from k8s pods (in case they are set)
  # and added  as extra attributes to the telemetry in the following format:
  # k8s.pod.labels.<label_name>: <label_value>
  podLabels: []
    # - app
    # - k8s-app
    # - release

  # List of hardcoded key/value pairs that will be added as attributes to
  # all the telemetry.
  custom: []
    # - name: "account_id"
    #   value: "1234567890"

################################################################################
# OPTIONAL CONFIGURATIONS OF PARTICULAR O11Y COLLECTOR COMPONENTS
################################################################################

################################################################################
# Open-telemetry collector running as an deamonset agent on every node.
# It collects metrics and traces and send them to Signalfx backend.
################################################################################

otelAgent:
  enabled: true

  # The ports to be exposed by the agent to the host.
  # Make sure that only necessary ports are exposed, <hostIP, hostPort, protocol> combination must
  # be unique across all the nodes in k8s cluster. Any port can be disabled,
  # For example to disable zipkin ports set `otelAgent.ports.zipkin: null`.
  ports:
    otlp:
      containerPort: 4317
      hostPort: 4317
      protocol: TCP
      enabled_for: [traces, metrics, logs]
    sfx-forwarder:
      containerPort: 9080
      hostPort: 9080
      protocol: TCP
      enabled_for: [traces]
    zipkin:
      containerPort: 9411
      hostPort: 9411
      protocol: TCP
      enabled_for: [traces]
    jaeger-thrift:
      containerPort: 14268
      hostPort: 14268
      protocol: TCP
      enabled_for: [traces]
    jaeger-grpc:
      containerPort: 14250
      hostPort: 14250
      protocol: TCP
      enabled_for: [traces]
    fluentforward:
      containerPort: 8006
      hostPort: 8006
      protocol: TCP
      enabled_for: [logs]
    signalfx:
      containerPort: 9943
      hostPort: 9943
      protocol: TCP
      enabled_for: [metrics]

  resources:
    limits:
      cpu: 200m
      # This value is being used as a source for default memory_limiter processor configurations
      memory: 500Mi

  securityContext: {}

  # OTel agent annotations
  annotations: {}
  podAnnotations: {}

  # OTel agent extra pod labels
  podLabels: {}

  # Extra enviroment variables to be set in the OTel agent container
  extraEnvs: []

  # Extra volumes to be mounted to the agent daemonset.
  # The volumes will be available for both OTel agent and fluentd containers.
  extraVolumes: []
  extraVolumeMounts: []

  # OpenTelemetry Collector configuration for otel-agent daemonset can be overriden in this field.
  # Default configuration defined in config/otel-agent-config.yaml
  # Any additional fields will be merged into the defaults,
  # existing fields can be disabled by setting them to null value.
  config: {}

################################################################################
# OpenTelemetry Kubernetes cluster receiver
# This is an extra 1-replica deployment of Open-temlemetry collector used
# specifically for collecting metrics from kubernetes API.
################################################################################

# Kubernetes cluster receiver collects cluster level metrics from the Kubernetes API.
# It has to be running on one pod, so it uses its own dedicated deployment with 1 replica.

otelK8sClusterReceiver:
  enabled: true

  # Need to be adjusted based on size of the monitored cluster
  resources:
    limits:
      cpu: 200m
      memory: 500Mi

  # Scheduling configurations
  nodeSelector: {}
  tolerations: []
  affinity: {}

  # Pod configurations
  securityContext: {}
  terminationGracePeriodSeconds: 600
  priorityClassName: ""

  # k8s cluster receiver collector annotations
  annotations: {}
  podAnnotations: {}

  # k8s cluster receiver extra pod labels
  podLabels: {}

  # Extra enviroment variables to be set in the OTel Cluster Receiver container
  extraEnvs: []

  # Extra volumes to be mounted to the k8s cluster receiver container.
  extraVolumes: []
  extraVolumeMounts: []

  # OpenTelemetry Collector configuration for K8s Cluster Receiver deployment can be overriden in this field.
  # Defaul configuration defined in config/otel-k8s-cluster-receiver-config.yaml
  # Any additional fields will be merged into the defaults,
  # existing fields can be disabled by setting them to null value.
  config: {}

################################################################################
# Fluentd configuration for logs collection
################################################################################

fluentd:
  resources:
    limits:
      cpu: 500m
      memory: 500Mi
    requests:
      cpu: 100m
      memory: 200Mi

  securityContext:
    runAsUser: 0

  # Extra enviroment variables to be set in the FluentD container
  extraEnvs: []

  config:
    # Configurations for container logs
    containers:
      # Path to root directory of container logs
      path: /var/log
      # Final volume destination of container log symlinks
      pathDest: /var/lib/docker/containers
      # Log format type, "json" or "cri".
      # If omitted (default), the value is detected automatically based on container runtime.
      # "json" is set if docker runtime detected, otherwise it defaults to "cri".
      logFormatType: ""
      # Specify the log format for "cri" logFormatType
      # It can be "%Y-%m-%dT%H:%M:%S.%N%:z" for openshift and "%Y-%m-%dT%H:%M:%S.%NZ" for IBM IKS
      criTimeFormat: "%Y-%m-%dT%H:%M:%S.%N%:z"

    # Directory where to read journald logs. (docker daemon logs, kubelet logs, and anyother specified serivce logs)
    journalLogPath: /run/log/journal

    # Controls the output buffer for the fluentd daemonset
    # Note that, for memory buffer, if `resources.limits.memory` is set,
    # the total buffer size should not bigger than the memory limit, it should also
    # consider the basic memory usage by fluentd itself.
    # All buffer parameters (except Argument) defined in
    # https://docs.fluentd.org/v1.0/articles/buffer-section#parameters
    # can be configured here.
    buffer:
      "@type": memory
      total_limit_size: 600m
      chunk_limit_size: 1m
      chunk_limit_records: 100000
      flush_interval: 5s
      flush_thread_count: 1
      overflow_action: block
      retry_max_times: 3

    # logLevel is to set log level of the Splunk log collector.
    # Available values are: trace, debug, info, warn, error
    logLevel: info

    # path of logfiles, default /var/log/containers/*.log
    path: /var/log/containers/*.log
    # paths of logfiles to exclude. object type is array as per fluentd specification:
    # https://docs.fluentd.org/input/tail#exclude_path
    excludePath:
    #  - /var/log/containers/kube-svc-redirect*.log
    #  - /var/log/containers/tiller*.log

    # Prefix for pos_file tail source parameter
    # Can be used if you want to run multiple instances of fluentd on the same host
    # https://docs.fluentd.org/input/tail#pos_file-highly-recommended
    posFilePrefix: /var/log/splunk-fluentd

    # `customFilters` defines the custom filters to be used.
    # This section can be used to define custom filters using plugins like https://github.com/splunk/fluent-plugin-jq
    # Its also possible to use other filters like https://www.fluentd.org/plugins#filter
    #
    # The scheme to define a custom filter is:
    #
    # ```
    # <name>:
    #   tag: <fluentd tag for the filter>
    #   type: <fluentd filter type>
    #   body: <definition of the fluentd filter>
    # ```
    #
    # = fluentd tag for the filter =
    # This is the fluentd tag for the record
    #
    # = fluentd filter type =
    # This is the fluentd filter that the user wants to use for record manipulation.
    #
    # = definition of the fluentd filter =
    # This defines the body/logic for using the filter for record manipulation.
    #
    # For example if you want to define a filter which sets cluster_name field to "my_awesome_cluster" you would the following filter
    # <filter tail.containers.**>
    #  @type jq_transformer
    #  jq '.record.cluster_name = "my_awesome_cluster" | .record'
    # </filter>
    # This can be defined in the customFilters section as follows:
    # ```
    # customFilters:
    #   NamespaceSourcetypeFilter:
    #     tag: tail.containers.**
    #     type: jq_transformer
    #     body: jq '.record.cluster_name = "my_awesome_cluster" | .record'
    # ```
    customFilters: {}

    # `logs` defines the source of logs, multiline support, and their sourcetypes.
    #
    # The scheme to define a log is:
    #
    # ```
    # <name>:
    #   from:
    #     <source>
    #   timestampExtraction:
    #     regexp: "<regexp_to_extract_timestamp_from_log>"
    #     format: "<format_of_the_timestamp>"
    #   multiline:
    #     firstline: "<regexp_to_detect_firstline_of_multiline>"
    #     flushInterval 5s
    #   sourcetype: "<sourcetype_of_logs>"
    # ```
    #
    # = <source> =
    # It supports 3 kinds of sources: journald, file, and container.
    # For `journald` logs, `unit` is required for filtering using _SYSTEMD_UNIT, example:
    # ```
    # docker:
    #   from:
    #     journald:
    #       unit: docker.service
    # ```
    #
    # For `file` logs, `path` is required for specifying where is the log files. Log files are expected in `/var/log`, example:
    # ```
    # docker:
    #   from:
    #     file:
    #       path: /var/log/docker.log
    # ```
    #
    # For `container` logs, `pod` field is required. It represents part of
    # the pod name, can be name of a deployment or replica set. Use "*" to
    # apply the configuration to all pods. Optional `container` value can be
    # used to apply configuration to a particular container.
    # ```
    # kube-apiserver:
    #   from:
    #     pod: kube-apiserver
    #
    # etcd:
    #   from:
    #     pod: etcd-server
    #     container: etcd-container
    # ```
    #
    # = timestamp =
    # `timestampExtraction` defines how to extract timestamp from logs. This *only* works for `file` source.
    # To use `timestampExtraction` you need to define both:
    # - `regexp`: the Regular Expression used to find the timestamp from a log entry.
    #             The timestamp part must be in a `time` named group. E.g.
    #             (?<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})
    # - `format`: a format string defintes how to parse the timestamp, e.g. "%Y-%m-%d %H:%M:%S".
    #             More details can be find: http://ruby-doc.org/stdlib-2.5.0/libdoc/time/rdoc/Time.html#method-c-strptime
    #
    # = multiline =
    # `multiline` options provide basic multiline support. Two options:
    # - `firstline`: a Regular Expression used to detect the first line of a multiline log.
    # - `flushInterval`: The interval between data flushes, default value: 5s.
    #
    # = sourcetype =
    # sourcetype of each kind of log can be defined using the `sourcetype` field.
    # If `sourcetype` is not defined, `name` will be used.
    #
    # ---
    # Here we have some default timestampExtraction and multiline settings for kubernetes components.
    # So, usually you just need to redefine the source of those components if necessary.
    logs:
      docker:
        from:
          journald:
            unit: docker.service
        timestampExtraction:
          regexp: time="(?<time>\d{4}-\d{2}-\d{2}T[0-2]\d:[0-5]\d:[0-5]\d.\d{9}Z)"
          format: "%Y-%m-%dT%H:%M:%S.%NZ"
        sourcetype: kube:docker
      kubelet: &glog
        from:
          journald:
            unit: kubelet.service
        timestampExtraction:
          regexp: \w(?<time>[0-1]\d[0-3]\d [^\s]*)
          format: "%m%d %H:%M:%S.%N"
        multiline:
          firstline: /^\w[0-1]\d[0-3]\d/
        sourcetype: kube:kubelet
      etcd:
        from:
          pod: etcd-server
          container: etcd-container
        timestampExtraction:
          regexp: (?<time>\d{4}-\d{2}-\d{2} [0-2]\d:[0-5]\d:[0-5]\d\.\d{6})
          format: "%Y-%m-%d %H:%M:%S.%N"
      etcd-minikube:
        from:
          pod: etcd-minikube
          container: etcd
        timestampExtraction:
          regexp: (?<time>\d{4}-\d{2}-\d{2} [0-2]\d:[0-5]\d:[0-5]\d\.\d{6})
          format: "%Y-%m-%d %H:%M:%S.%N"
      etcd-events:
        from:
          pod: etcd-server-events
          container: etcd-container
        timestampExtraction:
          regexp: (?<time>\d{4}-[0-1]\d-[0-3]\d [0-2]\d:[0-5]\d:[0-5]\d\.\d{6})
          format: "%Y-%m-%d %H:%M:%S.%N"
      kube-apiserver:
        <<: *glog
        from:
          pod: kube-apiserver
        sourcetype: kube:kube-apiserver
      kube-scheduler:
        <<: *glog
        from:
          pod: kube-scheduler
        sourcetype: kube:kube-scheduler
      kube-controller-manager:
        <<: *glog
        from:
          pod: kube-controller-manager
        sourcetype: kube:kube-controller-manager
      kube-proxy:
        <<: *glog
        from:
          pod: kube-proxy
        sourcetype: kube:kube-proxy
      kubedns:
        <<: *glog
        from:
          pod: kube-dns
        sourcetype: kube:kubedns
      dnsmasq:
        <<: *glog
        from:
          pod: kube-dns
        sourcetype: kube:dnsmasq
      dns-sidecar:
        <<: *glog
        from:
          pod: kube-dns
          container: sidecar
        sourcetype: kube:kubedns-sidecar
      dns-controller:
        <<: *glog
        from:
          pod: dns-controller
        sourcetype: kube:dns-controller
      kube-dns-autoscaler:
        <<: *glog
        from:
          pod: kube-dns-autoscaler
          container: autoscaler
        sourcetype: kube:kube-dns-autoscaler
      kube-audit:
        from:
          file:
            path: /var/log/kube-apiserver-audit.log
        timestampExtraction:
          format: "%Y-%m-%dT%H:%M:%SZ"
        sourcetype: kube:apiserver-audit

################################################################################
# Docker image configuration
################################################################################

image:
  # Secrets to attach to the respective serviceaccount to pull docker images
  imagePullSecrets: []

  fluentd:
    # The registry and name of the fluentd image to pull
    repository: splunk/fluentd-hec
    # The tag of the fluentd image to pull
    tag: 1.2.4
    # The policy that specifies when the user wants the fluentd images to be pulled
    pullPolicy: IfNotPresent

    initContainer:
      # The image of the container for fluentd init to pull
      image: busybox:1.33
      # The policy that specifies when the user wants the fluentd init image to be pulled
      pullPolicy: IfNotPresent

  otelcol:
    # The registry and name of the opentelemetry collector image to pull
    repository: quay.io/signalfx/splunk-otel-collector
    # The tag of the opentelemetry collector image to pull
    tag: 0.31.0
    # The policy that specifies when the user wants the opentelemetry collector images to be pulled
    pullPolicy: IfNotPresent


################################################################################
# Extra system configuration
################################################################################

## Limits how many pods may be unavailable due to voluntary disruptions.
## https://kubernetes.io/docs/tasks/run-application/configure-pdb/
podDisruptionBudget: {}
  # Minimum number of pods (as a number or percentage) that must remain available.
  # minAvailable:
  # Maximum number of pods (as a number or percentage) that can be unavailable.
  # maxUnavailable:

serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

  # Service account annotations
  annotations: {}

podSecurityPolicy:
  # Specifies whether Pod Security Policy resources should be created.
  # This should be set to `false` if either:
  # a) Pod Security Policies is not enabled in the cluster, or
  # b) you want to create Pod Security Policy resources by yourself.
  create: false

# Create or use existing secret if name is empty default name is used
secret:
  create: true
  name:

# This default tolerations allow the daemonset to be deployed on master nodes,
# so that we can also collect logs and metrics from those nodes.
tolerations:
  - key: node-role.kubernetes.io/master
    effect: NoSchedule

# Defines which nodes should be selected to deploy the o11y collector daemonset.
nodeSelector: {}
terminationGracePeriodSeconds: 600

# Defines node affinity to restrict deployment of the o11y collector daemonset.
affinity: {}

# Defines priorityClassName to assign a priority class to pods.
priorityClassName: ""


################################################################################
# OpenTelemetry "collector" k8s deployment configuration.
# This is an additional deployment of Open-telemetry collector that can be used
# to pass traces trough it, make k8s metadata enrichment and batching.
# Another use case is to point tracing instrumentation libraries directly to
# the collector endpoint instead of local agents. The collector running in the
# passthrough mode is recommended for large k8s clusters, disabled by default.
################################################################################

otelCollector:
  # Defines if collector deployment is enabled
  # Recommended for large k8s clusters, disabled by default.
  enabled: false

  # Number of collector replicas
  replicaCount: 3

  # The ports exposed by the collector container.
  # Any port can be disabled by setting to null.
  # Any changes should be aligned with service.ports configuration below.
  ports:
    otlp:
      containerPort: 4317
      protocol: TCP
      enabled_for: [metrics, traces, logs]
    jaeger-thrift:
      containerPort: 14268
      protocol: TCP
      enabled_for: [traces]
    jaeger-grpc:
      containerPort: 14250
      protocol: TCP
      enabled_for: [traces]
    zipkin:
      containerPort: 9411
      protocol: TCP
      enabled_for: [traces]
    signalfx:
      containerPort: 9943
      protocol: TCP
      # SignalFx metrics enabled in gateway for all telemetry types since there may be
      # bundled metrics.
      enabled_for: [metrics, traces, logs]
    http-forwarder:
      containerPort: 6060
      protocol: TCP
      # Enabled for all because SignalFx exporter will always send metadata updates when enabled.
      enabled_for: [metrics, traces, logs]

  resources:
    limits:
      cpu: 4
      # Memory limit value is used as a source for default memory_limiter configuration
      memory: 8Gi

  # Scheduling configurations
  nodeSelector: {}
  tolerations: []
  affinity: {}

  # Pod configurations
  securityContext: {}
  terminationGracePeriodSeconds: 600
  priorityClassName: ""

  # OTel collector annotations
  annotations: {}
  podAnnotations: {}

  # OTel collector extra pod labels
  podLabels: {}

  # Extra enviroment variables to be set in the standalone OTel collector container
  extraEnvs: []

  # Extra volumes to be mounted to the OTel Collector container.
  extraVolumes: []
  extraVolumeMounts: []

  # OpenTelemetry Collector configuration for standalone otel-collector deployment can be overriden in this field.
  # Default configuration defined in config/otel-collector-config.yaml
  # Any additional fields will be merged into the defaults,
  # existing fields can be disabled by setting them to `null`.
  config: {}

# This Flag allow to add necessary permissions to support all SmartAgent
# Kubernetes-related plugins and add missing key environmental variables.
k8sEventsEnabled: false

################################################################################
# OpenTelemetry service config, used for otel collector deployment.
# Disabled by default
################################################################################

# opentelemetry collector service created only if collector.enabled = true
service:
  # Service type
  type: ClusterIP
  # Service annotations
  annotations: {}
